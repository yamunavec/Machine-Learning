# -*- coding: utf-8 -*-
"""Project_Group2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x3hqBB3C-Gy2tedjSgR2iUngdDIgEy0W
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import warnings
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import scipy.stats as ss
from statsmodels.formula.api import ols
from scipy.stats import zscore
from sklearn import model_selection
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression  
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier
from sklearn.dummy import DummyClassifier

# %matplotlib inline
import io
from google.colab import files

warnings.filterwarnings('ignore')

col_names=['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points','Wilderness_Area1','Wilderness_Area2','Wilderness_Area3','Wilderness_Area4','Soil_Type1','Soil_Type2','Soil_Type3','Soil_Type4','Soil_Type5','Soil_Type6','Soil_Type7','Soil_Type8','Soil_Type9','Soil_Type10','Soil_Type11','Soil_Type12','Soil_Type13','Soil_Type14','Soil_Type15','Soil_Type16','Soil_Type17','Soil_Type18','Soil_Type19','Soil_Type20','Soil_Type21','Soil_Type22','Soil_Type23','Soil_Type24','Soil_Type25','Soil_Type26','Soil_Type27','Soil_Type28','Soil_Type29','Soil_Type30','Soil_Type31','Soil_Type32','Soil_Type33','Soil_Type34','Soil_Type35','Soil_Type36','Soil_Type37','Soil_Type38','Soil_Type39','Soil_Type40','Cover_Type']
ds=pd.read_csv('/content/covtype.csv',header=None,names=col_names)
ds.shape

ds.head()

print('Dimensions:')
print('Number of Records:', ds.shape[0])
print('Number of Features:', ds.shape[1])

ds.describe()

#checking missing values
print(list(ds.isnull().any()))

#cover type count and visualization
ds.Cover_Type.value_counts()

sns.countplot(x='Cover_Type',data=ds)
plt.show()

#finding skew
print(ds.skew())

skew=ds.skew()
skew_data=pd.DataFrame(skew,index=None,columns=['Skewness'])
plt.figure(figsize=(13,6))
sns.barplot(x=skew_data.index,y='Skewness',data=skew_data)
plt.xticks(rotation=90)

cont_data=ds.loc[:,'Elevation':'Horizontal_Distance_To_Fire_Points']

binary_data=ds.loc[:,'Wilderness_Area1':'Soil_Type40']

Wilderness_data=ds.loc[:,'Wilderness_Area1': 'Wilderness_Area4']

Soil_data=ds.loc[:,'Soil_Type1':'Soil_Type40']

#preprocessing

min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(cont_data)
finalds = pd.DataFrame(x_scaled)
finalds
ds['Elevation'] = finalds[0]
ds['Aspect'] = finalds[1]
ds['Slope'] = finalds[2]
ds['Horizontal_Distance_To_Hydrology'] = finalds[3]
ds['Vertical_Distance_To_Hydrology'] = finalds[4]
ds['Horizontal_Distance_To_Roadways'] = finalds[5]
ds['Hillshade_9am'] = finalds[6]
ds['Hillshade_Noon'] = finalds[7]
ds['Hillshade_3pm'] = finalds[8]
ds['Horizontal_Distance_To_Fire_Points'] = finalds[9]
print(ds)

#count of wilderness area and soil type
for col in binary_data:
    count=binary_data[col].value_counts()
    print(col,count)

#determing the features with count less than 1000
for col in binary_data:
    count=binary_data[col].value_counts()[1] 
    if count < 1000:
        print(col,count)

#visualization of continuous data
col = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',
       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',
       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',
       'Horizontal_Distance_To_Fire_Points']
train = ds[col]
train.hist(figsize=(13, 11))
plt.show()

#box plot
plt.style.use('ggplot')
for i in col:
    plt.figure(figsize=(11, 7))
    plt.title(str(i) + " with " + str('Cover_Type'))
    sns.boxplot(x=ds.Cover_Type, y=train[i])
    plt.show()

#visualizing binary features
for i, col in enumerate(binary_data.columns):
    plt.figure(i,figsize=(6,4))
    sns.countplot(x=col, hue=ds['Cover_Type'] ,data=ds, palette="rocket")

#correlation analysis
plt.figure(figsize=(12, 10))
sns.heatmap(cont_data.corr(),cmap='Greens',linecolor='white',linewidths=1,annot=True)

#checking skewness of non-boolean type
ds.iloc[:,:10].skew()

#Horizontal_Distance_To_Hydrology
from scipy import stats
plt.figure(figsize=(6,6))
sns.distplot(ds['Horizontal_Distance_To_Hydrology'], fit = stats.norm)
fig = plt.figure(figsize=(6,6))
res = stats.probplot(ds['Horizontal_Distance_To_Hydrology'], plot=plt)

ds['Horizontal_Distance_To_Hydrology'] = np.sqrt(ds['Horizontal_Distance_To_Hydrology'])
# Plot after sqrt transformation
plt.figure(figsize=(6,6))
sns.distplot(ds['Horizontal_Distance_To_Hydrology'], fit = stats.norm)
fig = plt.figure(figsize=(6,6))
res = stats.probplot(ds['Horizontal_Distance_To_Hydrology'], plot=plt)

#Vertical_Distance_To_Hydrology
plt.figure(figsize=(6,6))
sns.distplot(ds['Vertical_Distance_To_Hydrology'], fit = stats.norm)
fig = plt.figure(figsize=(6,6))
res = stats.probplot(ds['Vertical_Distance_To_Hydrology'], plot=plt)

#Horizontal_Distance_To_Roadways
plt.figure(figsize=(6,6))
sns.distplot(ds['Horizontal_Distance_To_Roadways'], fit=stats.norm)
fig = plt.figure(figsize=(6,6))
res = stats.probplot(ds['Horizontal_Distance_To_Roadways'], plot=plt)

ds['Horizontal_Distance_To_Roadways'] = np.sqrt(ds['Horizontal_Distance_To_Roadways'])
plt.figure(figsize=(6,6))
sns.distplot(ds['Horizontal_Distance_To_Roadways'], fit = stats.norm)
fig = plt.figure(figsize=(6,6))
res = stats.probplot(ds['Horizontal_Distance_To_Roadways'], plot=plt)

#Hillshade_9am
fig = plt.figure(figsize=(6,6))
sns.distplot(ds['Hillshade_9am'],fit=stats.norm)
fig = plt.figure(figsize=(6,6))
res = stats.probplot(ds['Hillshade_9am'],plot=plt)

ds['Hillshade_9am'] = np.square(ds['Hillshade_9am'])
plt.figure(figsize=(6,6))
sns.distplot(ds['Hillshade_9am'], fit = stats.norm)
fig = plt.figure(figsize=(6,6))
res = stats.probplot(ds['Hillshade_9am'], plot=plt)

# Hillshade_Noon
fig = plt.figure(figsize=(6,6))
sns.distplot(ds['Hillshade_Noon'],fit=stats.norm)
fig = plt.figure(figsize=(6,6))
res = stats.probplot(ds['Hillshade_Noon'],plot=plt)

ds['Hillshade_Noon'] = np.square(ds['Hillshade_Noon'])
#fig = plt.figure(figsize=(6,6))
#sns.distplot(ds['Hillshade_Noon'],fit=stats.norm)
fig = plt.figure(figsize=(6,6))
res = stats.probplot(ds['Hillshade_Noon'],plot=plt)

# Horizontal_Distance_To_Fire_Points
plt.figure(figsize=(8,6))
sns.distplot(ds['Horizontal_Distance_To_Fire_Points'], fit=stats.norm)
plt.figure(figsize=(8,6))
res = stats.probplot(ds['Horizontal_Distance_To_Fire_Points'],plot=plt)

ds['Horizontal_Distance_To_Fire_Points'] = np.sqrt(ds['Horizontal_Distance_To_Fire_Points'])
plt.figure(figsize=(6,6))
sns.distplot(ds['Horizontal_Distance_To_Fire_Points'], fit=stats.norm)
plt.figure(figsize=(6,6))
res = stats.probplot(ds['Horizontal_Distance_To_Fire_Points'],plot=plt)

ds_test1=ds
ds_test1[['Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Fire_Points','Horizontal_Distance_To_Roadways']] = np.sqrt(ds_test1[['Horizontal_Distance_To_Hydrology',
        'Horizontal_Distance_To_Fire_Points','Horizontal_Distance_To_Roadways']])
ds_test1[['Hillshade_9am','Hillshade_Noon']] = np.sqrt(ds_test1[['Hillshade_9am','Hillshade_Noon']])
print(ds_test1)

#reverse one hot encoding for soil type
soil_ds=ds.loc[:,'Soil_Type1':'Soil_Type40']
def rev_code(row):
    for c in soil_ds.columns:
        if row[c]==1:
            return c  

ds['Soil_Type']=soil_ds.apply(rev_code, axis=1)

#reverse one hot encoding for wilderness area
def rev_code(row):
    for c in Wilderness_data.columns:
        if row[c]==1:
            return c  

ds['Wilderness_Type']=Wilderness_data.apply(rev_code, axis=1)

plt.figure(figsize=(16,8))
sns.countplot(x='Wilderness_Type', hue='Cover_Type',data=ds, palette="rocket")
plt.xticks(rotation=90)

plt.figure(figsize=(16,8))
sns.countplot(x='Soil_Type', hue='Cover_Type',data=ds, palette="rocket")
plt.xticks(rotation=90)

#storing target and other features
X=ds.loc[:,'Elevation':'Soil_Type40']
y=ds['Cover_Type']

#removing features based on correlation analysis and SD
rem=['Hillshade_3pm','Soil_Type7','Soil_Type8','Soil_Type14','Soil_Type15',
     'Soil_Type21','Soil_Type25','Soil_Type28','Soil_Type36','Soil_Type37']

X.drop(rem, axis=1, inplace=True)

#splitting data into train and test split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=101)

classification_accuracy = []
classification_precision = []
classification_recall = []
classification_f1score = []

M = [LinearSVC() , DecisionTreeClassifier() , LogisticRegression() , GaussianNB() ,RandomForestClassifier() , 
     GradientBoostingClassifier()]
X = ["LinearSVC" , "DecisionTreeClassifier" , "LogisticRegression" , "GaussianNB" ,"RandomForestClassifier" , 
     "GradientBoostingClassifier"]

for i in range(0,len(M)):
    model = M[i]
    model.fit( X_train , y_train )
    pred = model.predict(X_test)
    classification_accuracy.append(accuracy_score(pred , y_test))   
    classification_precision.append(precision_score(pred, y_test, average='weighted'))
    classification_recall.append(recall_score(pred, y_test, average='weighted'))
    classification_f1score.append(f1_score(pred, y_test, average='weighted'))
    
    cm = confusion_matrix(pred, y_test) 
    cm_df = pd.DataFrame(cm, range(1,8),range(1,8))
    plt.figure(figsize = (10,8))
    sns.set(font_scale=1.2)
    sns.heatmap(cm_df,annot=True,fmt='g')
    
    
d = { "Algorithm" : X, "Accuracy" : classification_accuracy, "Precision" : classification_precision, "Recall" : classification_recall, "F1 score" : classification_f1score}

dtfm = pd.DataFrame(d)
dtfm

from sklearn import metrics
from sklearn.metrics import classification_report
knn=KNeighborsClassifier(n_neighbors=5)
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=101)
knn.fit(X_train,y_train)
y_pred=knn.predict(X_test)
print("Accuracy:",metrics.accuracy_score(y_test,y_pred))
print(classification_report(y_test, y_pred))

cm=confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.set(font_scale=1.2)
sns.heatmap(cm, annot=True, fmt='g')
plt.show()

#cross validation for some classifiers
models = []
models.append(('LR', LogisticRegression()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', LinearSVC()))
results = []
names = []
seed = 7
scoring = 'accuracy'
for name, model in models:
	kfold = model_selection.KFold(n_splits=10, random_state=seed)
	cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
	results.append(cv_results)
	names.append(name)
	msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
	print(msg)

models = []
models.append(('RDF',RandomForestClassifier(n_estimators=100)))
models.append(('KNN', KNeighborsClassifier(n_neighbors=5)))
results = []
names = []
seed = 7
scoring = 'accuracy'
for name, model in models:
	kfold = model_selection.KFold(n_splits=10, random_state=seed)
	cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
	results.append(cv_results)
	names.append(name)
	msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
	print(msg)

#Combining KNN and Random Forest for Voting
from sklearn.ensemble import VotingClassifier
model1 = KNeighborsClassifier(n_neighbors=5)
model2 = RandomForestClassifier(n_estimators=100, random_state=0)
ensemble_model = VotingClassifier(estimators=[('KNN', model1), ('RDF', model2)], voting='hard')
ensemble_model.fit(X_train,y_train)
pred_ensemble=ensemble_model.predict(X_test)
print(accuracy_score(pred_ensemble,y_test))

#performance metrics and confusion matrix
Precision  = precision_score(pred_ensemble, y_test, average='weighted')
Recall = recall_score(pred_ensemble, y_test, average='weighted')
f1score = f1_score(pred_ensemble, y_test, average='weighted')
cm = confusion_matrix(pred_ensemble, y_test)
print('Voting Precision:',Precision)
print('Voting Recall:',Recall)
print('Voting F1score:',f1score)
print(cm)

cm_df = pd.DataFrame(cm, range(1,8), range(1,8))
plt.figure(figsize = (10,8))
sns.set(font_scale=1.2)
sns.heatmap(cm_df,annot=True,fmt='g')

#Bagging
from sklearn.ensemble import BaggingClassifier
from sklearn import tree
model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))
model.fit(X_train, y_train)
model.score(X_test,y_test)
pred_bagging=model.predict(X_test)
print(accuracy_score(pred_bagging,y_test))

#performance metrics and confusion matrix
Precision  = precision_score(pred_bagging, y_test, average='weighted')
Recall = recall_score(pred_bagging, y_test, average='weighted')
f1score = f1_score(pred_bagging, y_test, average='weighted')
cm = confusion_matrix(pred_bagging, y_test)
print('Bagging Precision:',Precision)
print('Bagging Recall:',Recall)
print('Bagging F1score:',f1score)
print(cm)

cm_df = pd.DataFrame(cm, range(1,8), range(1,8))
plt.figure(figsize = (10,8))
sns.set(font_scale=1.2)
sns.heatmap(cm_df,annot=True,fmt='g')

#oversampling
from imblearn.over_sampling import SMOTE
smote = SMOTE(ratio='minority')
X_sm, y_sm = smote.fit_sample(X_train, y_train)
X_sm_df=pd.DataFrame(X_sm)
print(X_sm_df.index)

#KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_sm,y_sm)
pred = knn.predict(X_test)
Accuracy=knn.score(X_test,y_test)
Precision  = precision_score(pred, y_test, average='weighted')
Recall = recall_score(pred, y_test, average='weighted')
f1score = f1_score(pred, y_test, average='weighted')
cm = confusion_matrix(pred, y_test)
print('KNN Accuracy:',Accuracy)
print('KNN Precision:',Precision)
print('KNN Recall:',Recall)
print('KNN F1score:',f1score)
print(cm)

cm_df = pd.DataFrame(cm, range(1,8), range(1,8))
plt.figure(figsize = (10,8))
sns.set(font_scale=1.2)
sns.heatmap(cm_df,annot=True,fmt='g')

#other classifiers
classifier_accuracy = []
classifier_precision = []
classifier_recall = []
classifier_f1score = []

M = [LinearSVC() , DecisionTreeClassifier() , LogisticRegression() , GaussianNB() ,RandomForestClassifier() , 
     GradientBoostingClassifier()]
X = ["LinearSVC" , "DecisionTreeClassifier" , "LogisticRegression" , "GaussianNB" ,"RandomForestClassifier" , 
     "GradientBoostingClassifier"]

for i in range(0,len(Z)):
    model = Z[i]
    model.fit( X_sm , y_sm )
    pred = model.predict(X_test)
    classifier_accuracy.append(accuracy_score(pred , y_test))   
    classifier_precision.append(precision_score(pred, y_test, average='weighted'))
    classifier_recall.append(recall_score(pred, y_test, average='weighted'))
    classifier_f1score.append(f1_score(pred, y_test, average='weighted'))
    
    cm = confusion_matrix(pred, y_test)
    cm_df = pd.DataFrame(cm, range(1,8),range(1,8))
    plt.figure(figsize = (10,8))
    sns.set(font_scale=1.2)
    sns.heatmap(cm_df,annot=True,fmt='g')
    
    
d = { "Algorithm" : X, "Accuracy" : classifier_accuracy, "Precision" : classifier_precision, "Recall" : classifier_recall, "F1 score" : classifier_f1score}

df = pd.DataFrame(d)
df

#undersampling
from imblearn.under_sampling import RandomUnderSampler
rs = RandomUnderSampler(return_indices=True)
X_rs, y_rs, id_rs = rs.fit_sample(X_train, y_train)
X_rs_df=pd.DataFrame(X_rs)
print(X_rs_df.index)

#KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_rus,y_rus)
pred = knn.predict(X_test)
Accuracy=knn.score(X_test,y_test)
Precision  = precision_score(pred, y_test, average='weighted')
Recall = recall_score(pred, y_test, average='weighted')
f1score = f1_score(pred, y_test, average='weighted')
cm = confusion_matrix(pred, y_test)
print('KNN Accuracy:',Accuracy)
print('KNN Precision:',Precision)
print('KNN Recall:',Recall)
print('KNN F1score:',f1score)
print(cm)

cm_df = pd.DataFrame(cm, range(1,8), range(1,8))
plt.figure(figsize = (10,8))
sns.set(font_scale=1.2)
sns.heatmap(cm_df,annot=True,fmt='g')

#other classifers
classifier_accuracy = []
classifier_precision = []
classifier_recall = []
classifier_f1score = []

M = [LinearSVC() , DecisionTreeClassifier() , LogisticRegression() , GaussianNB() ,RandomForestClassifier() , 
     GradientBoostingClassifier()]
X = ["LinearSVC" , "DecisionTreeClassifier" , "LogisticRegression" , "GaussianNB" ,"RandomForestClassifier" , 
     "GradientBoostingClassifier"]

for i in range(0,len(M)):
    model = M[i]
    model.fit( X_rs , y_rs )
    pred = model.predict(X_test)
    classifier_accuracy.append(accuracy_score(pred , y_test))   
    classifier_precision.append(precision_score(pred, y_test, average='weighted'))
    classifier_recall.append(recall_score(pred, y_test, average='weighted'))
    classifier_f1score.append(f1_score(pred, y_test, average='weighted'))
    
    cm = confusion_matrix(pred, y_test)
    cm_df = pd.DataFrame(cm, range(1,8),range(1,8))
    plt.figure(figsize = (10,8))
    sns.set(font_scale=1.2)
    sns.heatmap(cm_df,annot=True,fmt='g')
    
    
d = { "Algorithm" : X, "Accuracy" : classifier_accuracy, "Precision" : classifier_precision, "Recall" : classifier_recall, "F1 score" : classifier_f1score}

df = pd.DataFrame(d)
df

#oversampling
X=ds.loc[:,'Elevation':'Soil_Type40']
y=ds['Cover_Type']
from imblearn.over_sampling import SMOTE
smote=SMOTE(ratio='minority')
X_s, y_s = smote.fit_sample(X,y)
smote_df=pd.DataFrame(X_s,columns=X.columns)
cont_df=smote_df.iloc[:, :10]
skew=cont_df.skew()
skew_df=pd.DataFrame(skew, index=None, columns=['Skewness'])
plt.figure(figsize=(15,6))
sns.barplot(x=skew_df.index,y='Skewness',data=skew_df)
plt.xticks(rotation=90)
plt.show()



#undersampling
from imblearn.under_sampling import RandomUnderSampler
rs=RandomUnderSampler(return_indices=True)
X_rs, y_rs,rs_id = rs.fit_sample(X,y)
undersample_df=pd.DataFrame(X_rs,columns=X.columns)
cont_df=undersample_df.iloc[:, :10]
skew=cont_df.skew()
skew_df=pd.DataFrame(skew, index=None, columns=['Skewness'])
plt.figure(figsize=(15,6))
sns.barplot(x=skew_df.index,y='Skewness',data=skew_df)
plt.xticks(rotation=90)
plt.show()

from math import sqrt
from numpy.random import seed
from numpy.random import randn
from numpy import mean
from scipy.stats import sem
from scipy.stats import t
 
data1=ds.loc[:,'Elevation':'Soil_Type40']
data2=ds['Cover_Type']
# function for calculating the t-test for two independent samples
def independent_ttest(data1, data2, alpha):
	# calculate means
	mean1, mean2 = mean(data1), mean(data2)
	# calculate standard errors
	se1, se2 = sem(data1), sem(data2)
	# standard error on the difference between the samples
	sed = sqrt(se1**2.0 + se2**2.0)
	# calculate the t statistic
	t_stat = (mean1 - mean2) / sed
	# degrees of freedom
	df = len(data1) + len(data2) - 2
	# calculate the critical value
	cv = t.ppf(1.0 - alpha, df)
	# calculate the p-value
	p = (1.0 - t.cdf(abs(t_stat), df)) * 2.0
	# return everything
	return t_stat, df, cv, p
 
# seed the random number generator
seed(1)
# generate two independent samples
data1 = 5 * randn(100) + 50
data2 = 5 * randn(100) + 51
# calculate the t test
alpha = 0.05
t_stat, df, cv, p = independent_ttest(data1, data2, alpha)
print('t=%.3f, df=%d, cv=%.3f, p=%.3f' % (t_stat, df, cv, p))
# interpret via critical value
if abs(t_stat) <= cv:
	print('Accept null hypothesis that the means are equal.')
else:
	print('Reject the null hypothesis that the means are equal.')
# interpret via p-value
if p > alpha:
	print('Accept null hypothesis that the means are equal.')
else:
	print('Reject the null hypothesis that the means are equal.')